\chapter{Related Work}

\section{Why Johnny Can't Pentest Related Work}
\label{sec:related_work}

Our work is related to two main areas of research: the design of 
web applications for assessing vulnerability analysis tools and the
evaluation of web scanners.

\noindent {\bf Designing test web applications.} 
Vulnerable test applications are required to assess 
web vulnerability scanners. Unfortunately, no standard
test suite is currently available or accepted by the industry. 
HacmeBank~\cite{hacme_bank} and WebGoat~\cite{owasp-webgoat} are two
well-known, publicly-available, vulnerable web applications, but their
design is focused more on teaching web application security rather
than testing automated scanners. 
SiteGenerator~\cite{owasp_sitegenerator} is a tool to
generate sites with certain characteristics (e.g., classes of
vulnerabilities) according to its input configuration. 
While SiteGenerator is useful to automatically produce different vulnerable
sites, we found it easier to manually introduce in Wacko\-Picko the
vulnerabilities with the characteristics that we wanted to test.

\noindent {\bf Evaluating web vulnerability scanners.}
There exists a growing body of literature on the evaluation of web
vulnerability scanners. For example, 
Suto compared three scanners against three different applications and
used code coverage, among other metrics, as a measure of the
effectiveness of each scanner~\cite{suto07}. In a recent follow-up study,
Suto~\cite{suto10:webscanners} assessed seven scanners and compared
their detection capabilities and the time required to run them.
Wiegenstein et al. ran five unnamed scanners against a custom
benchmark~\cite{wiegenstein06}. Unfortunately, the authors do not discuss in
detail the reasons for detections or spidering failures.
In their survey of web security assessment tools, Curphey
and Araujo reported that black-box scanners perform
poorly~\cite{curphey06}.
Peine examined in depth the functionality and user interfaces of seven
scanners (three commercial) that were run against WebGoat
and one real-world application~\cite{peine06}.
Kals et al. developed a new web vulnerability scanner and tested it on
about 25,000 live web pages~\cite{kals06:secubat}. Since no ground
truth is available for these sites, the authors cannot discuss false
negative rate or failures of their tool.
More recently, AnantaSec released an evaluation of three scanners against
13 real-world applications, three web applications provided by the 
scanners vendors, and a series of JavaScript tests~\cite{anantasec09}. 
While this experiment assesses a large number of real-world
applications, only a limited number of scanners are tested and no
explanation is given for the results.
In addition, Vieira et al. tested four web scanners on 300 web
services~\cite{vieira09}. They also report high rates of false
positives and false negatives.

In comparison, our work, to the best of our knowledge, performs the largest evaluation of web
application scanners in terms of the number of tested tools (eleven,
both commercial and open-source), and the class of vulnerabilities analyzed.
In addition, we discuss the effectiveness of different
configurations and levels of manual intervention, and examine in detail
the reasons for a scanner's success or failure.

Furthermore, we provide a discussion of challenges (i.e., critical
limitations) of current web vulnerability scanners. While some of these
problem areas were discussed before ~\cite{grossman04,mcallister08}, we provide quantitative
evidence that these issues are actually limiting the performance of
today's tools.
We believe that this discussion will provide useful insight into
how to improve state-of-the-art of black-box web vulnerability scanners.

\section{Enemy of the State Related Work}

Automatic or semi-automatic web application vulnerability scanning has been a
hot topic in research for many years because of its relevance and its
complexity. 

Huang et al.\ developed a tool (WAVES) for assessing web application
security with which we share many points~\cite{huang03:web}. Similarly to us, they have a scanner
for finding the entry points in the web application by mimicking the behavior of
a web browser. They employ a learning mechanism to sensibly fill
web form fields and allow deep crawling of pages behind forms. Attempts to
discover vulnerabilities are carried out by submitting the same form multiple
times with valid, invalid, and faulty inputs, and comparing the result pages.
Differently from WAVES, we are using the knowledge gathered by the first-phase
scanner to help the fuzzer detect the effect of a given input. Moreover,
our first-phase scanner aims not only at finding relevant entry-points, but
rather at building a complete state-aware navigational map of the web
application.

A number of tools have been developed to try to automatically discover
vulnerabilities in web applications, produced as academic
prototypes~\cite{kals06:secubat, halfond09:penetration, jovanovic10:static,
huang04:securing, balzarotti08:saner, felmetsger10:logic, li12:sentinel}, as open-source
projects~\cite{w3af, grendelscan, paros}, or as commercial
products~\cite{acunetix, appscan, burp, webinspect}.

Multiple projects~\cite{bau10:state, suto10:webscanners,
  vieira09} tackled the task of evaluating the effectiveness of popular
black-box scanners (in some cases also called \emph{point-and-shoot} scanners).
The common theme in their results is a relevant discrepancy in vulnerabilities
found across scanners, along with low accuracy. Authors of these evaluations
acknowledge the difficulties and challenges of the
task~\cite{grossman04, vieira09}. In particular, we
highlighted how more deep crawling and reverse engineering capabilities of web
applications are needed in black-box scanners, and we also developed the
\emph{WackoPicko} web application which contains known vulnerabilities described in Chapter~\ref{why-johnny-cant-pentest}. Similarly, Bau
et al.\ investigated the presence of room for research in this area, and found
improvement is needed, in particular for detecting second-order XSS and SQL
injection attacks~\cite{bau10:state}.

%\cite{doupe2010johnny} evaluation of blackbox scanners again wackopicko:
%challenging task, many vulnerbailities are overlooked, more deep crawling and
%reverse engineering needed
%
%SSP10 \cite{bau10:state} blackbox scanner evaluation, room for improvement,
%second order XSS and SQLI, by increasing observaility.
%
%\cite{suto10:webscanners} many discrepancies across scanners, many
%vulnerbailities missed, work needed to improove accuracy
%
%\cite{vieira09} commercial scanners evaulation, difficult task, low
%accuracy
%
%\cite{grossman04} presentation about the challenges

Reverse engineering of web applications has not been widely explored
in the literature, to our knowledge. Some approaches~\cite{di02:ware} perform static analysis on the code to create UML
diagrams of the application.

Static analysis, in fact, is the technique mostly employed for automatic
vulnerability detection, often combined with dynamic analysis.

Halfond et al.\ developed a traditional black-box vulnerability
scanner, but improved its result by leveraging a static analysis technique to
better identify input vectors~\cite{halfond09:penetration}.

\emph{Pixy}~\cite{jovanovic10:static} employed static analysis with
taint propagation in order to detect SQL injection, XSS and shell command
injection, while \emph{Saner}~\cite{balzarotti08:saner} used sound
static analysis to detect failures in sanitization routines. Saner
also takes advantage of a second phase of dynamic analysis to reduce
false positives. Similarly, \emph{WebSSARI}~\cite{huang04:securing}
also employed static analysis for detecting injection vulnerabilities,
but, in addition, it proposed a technique for runtime
instrumentation of the web application through the insertion of proper
sanitization routines.

Felmetsger et al.\ investigated an approach for detecting a different type of
vulnerability (some categories of logic flaws) by combining
execution traces and symbolic model checking~\cite{felmetsger10:logic}. Similar
approaches are also used for generic bug finding (in fact, vulnerabilities
could be considered a subset of the general bug category). Csallner et
al.\ employ dynamic traces for bug finding and for dynamic verification of the
alerts generated by the static analysis phase~\cite{csallner08:dsd}. Artzi et
al., on the other hand, use symbolic execution and model checking for finding
general bugs in web applications~\cite{artzi10:finding}.

On a completely separate track, efforts to improve web application security
push the developers toward writing secure code in the first place. Security
experts are tying to achieve this goal by either educating the
developers~\cite{spi02:complete} or designing frameworks which prohibit the use
of bad programming practices and enforce some security constraints in the code.
Robertson and Vigna developed a strongly-typed framework which statically
enforces separation between structure and content of a web page, preventing XSS
and SQL injection~\cite{robertson09}. Also Chong et al.\ designed their
language for developers to build web applications with strong confidentiality
and integrity guarantees, by means of compile-time and run-time checks~\cite{chong07}.

Alternatively, consequences of vulnerabilities in web applications can be
mitigated by trying to prevent the attacks before they reach some potentially
vulnerable code, like, for example, in the already mentioned
\emph{WebSSARI}~\cite{huang04:securing} work. A different approach for
blocking attacks is followed by Scott and Sharp, who developed a language for
specifying a security policy for the web application; a gateway will then
enforce these policies~\cite{scott02}.

Another interesting research track deals with the problem of how to explore web
pages behind forms, also called the \emph{hidden
  web}~\cite{raghavan01:hidden-web}. McAllister et al.\ monitor user
interactions with a web application to collect sensible values for HTML form
submission and generate test cases that can be replayed to increase code
coverage~\cite{mcallister08}. Although not targeted to security
goals, the work of Raghavan and Garcia-Molina is relevant for our project for
their contribution in classification of different types of dynamic content and
for their novel approach for automatically filling forms by deducing the domain
of form fields~\cite{raghavan01:hidden-web}. Raghavan and Garcia-Molina carried
out further research in this direction, by reconstructing complex and
hierarchical query interfaces exposed by web applications.

Moreover, Amalfitano et al.\ started tackling the problem of reverse engineering
the state machine of client-side AJAX code, which will help in finding the web
application server-side entry points and in better understating complex and
hierarchical query interfaces~\cite{amalfitano08}.

Finally, we need to mention the work by Berg et al.\ in reversing state
machines into a \emph{Symbolic Mealy Machine} (SMM)
model~\cite{berg08}. Their approach for reversing machines
cannot be directly applied to our case because of the infeasibility of fully
exploring all pages for all the states, even for a small subset of the possible
states. Nevertheless, the model they propose for a SMM fits our needs.
